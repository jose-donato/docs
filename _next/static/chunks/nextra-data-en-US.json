{"/blog":{"title":"Blog","data":{"":"Blog\n\n\nThe latest updates and releases from the Turbo team at Vercel."}},"/":{"data":{"":""}},"/sdk":{"data":{"":""}},"/sdk/docs/core-concepts":{"title":"Core Concepts","data":{"":"Letâ€™s dive deep into the internals of Turbopack to figure out why itâ€™s so fast.","the-turbo-engine#The Turbo engine":"Turbopack is so fast because itâ€™s built on a reusable library for Rust which enables incremental computation known as the Turbo engine. Hereâ€™s how it works:","function-level-caching#Function-level caching":"In a Turbo engine-powered program, you can mark certain functions as â€˜to be rememberedâ€™. When these functions are called, the Turbo engine will remember what they were called with, and what they returned. Itâ€™ll then save it in an in-memory cache.Hereâ€™s a simplified example of what this might look like in a bundler:\n\nWe start with calling readFile on two files, api.ts and sdk.ts. We then bundle those files, concat them together, and end up with the fullBundle at the end. The results of all of those function calls get saved in the cache for later.Letâ€™s imagine that weâ€™re running on a dev server. You save the sdk.ts file on your machine. Turbopack receives the file system event, and knows it needs to recompute readFile(\"sdk.ts\"):\n\nSince the result of sdk.ts has changed, we need to bundle it again, which then needs to be concatenated again.Crucially, api.ts hasnâ€™t changed. We read its result from the cache and pass that to concat instead. So we save time by not reading it and re-bundling it again.Now imagine this in a real bundler, with thousands of files to read and transformations to execute. The mental model is the same. You can save enormous amounts of work by remembering the result of function calls and not re-doing work thatâ€™s been done before.","the-cache#The cache":"The Turbo engine currently stores its cache in memory. This means the cache will last as long as the process running it - which works well for a dev server. When you run next dev --turbo in Next v13, youâ€™ll start a cache with the Turbo engine. When you cancel your dev server, the cache gets cleared.In the future, weâ€™re planning to persist this cache - either to the filesystem, or to a remote cache like Turborepoâ€™s. This will mean that Turbopack could remember work done across runs and machines.","how-does-it-help#How does it help?":"This approach makes Turbopack extremely fast at computing incremental updates to your apps. This optimizes Turbopack for handling updates in development, meaning your dev server will always respond snappily to changes.In the future, a persistent cache will open the door to much faster production builds. By remembering work done across runs, new production builds could only rebuild changed files - potentially leading to enormous time savings.","compiling-by-request#Compiling by Request":"The Turbo engine helps provide extremely fast updates on your dev server, but thereâ€™s another important metric to consider - startup time. The faster your dev server can start running, the faster you can get to work.There are two ways to make a process faster - work faster, or do less work. For starting up a dev server, the way to do less work is to compile only the code thatâ€™s needed to get started.","page-level-compilation#Page-level compilation":"Versions of Next.js from 2-3 years ago used to compile the entire application before showing your dev server. In Next.js [11], we began compiling only the code on the page you requested.Thatâ€™s better, but itâ€™s not perfect. When you navigate to /users, weâ€™ll bundle all the client and server modules, dynamic-imported modules, and referenced CSS and images. That means if a large part of your page is hidden from view, or hidden behind tabs, weâ€™ll still compile it anyway.","request-level-compilation#Request-level compilation":"Turbopack is smart enough to compile only the code you request. That means if a browser requests HTML, we compile only the HTML - not anything that is referenced by the HTML.If a browser wants some CSS, weâ€™ll compile only that - without compiling referenced images. Got a big charting library behind next/dynamic? Doesnâ€™t compile it until the tab showing the chart is shown. Turbopack even knows to not compile source maps unless your Chrome DevTools are open.If we were to use native ESM, weâ€™d get similar behavior. Except that Native ESM produces a lot of requests to the server, as discussed in our Why Turbopack section. With request-level compilation, we get to both reduce the number of requests and use native speed to compile them. As you can see in our benchmarks, this provides significant performance improvements."}},"/sdk/docs/features":{"title":"Features","data":{"":"The practice of building web applications is enormously diverse. In CSS alone, you have SCSS, Less, CSS Modules, PostCSS, and hundreds of other libraries. Frameworks like React, Vue and Svelte require custom setups.When building a bundler, we needed to consider which features would be:\nBuilt-in: they work out of the box, no config required\nAvailable via plugins: usually installed from a registry and configured\nUnavailable: not available at all\n\nTurbopack is in alpha, so very few of these decisions are set in stone. In its current state, Turbopack cannot yet be configured - so plugins are not available yet.Let's discuss which features are available out-of-the-box, in Turbopack's default configuration. We'll also touch on features which will be configurable via plugins."}},"/sdk/docs":{"title":"Quickstart","data":{"":"Turbopack is an incremental bundler optimized for JavaScript and TypeScript, written in Rust by the creators of Webpack and Next.js at Vercel.On large applications Turbopack updates 10x faster than Vite and 700x faster than Webpack. For the biggest applications the difference grows even more stark with updates up to 20x faster than Vite.The secret to Turbopack's performance is twofold: highly optimized machine code and a low-level incremental computation engine that enables caching down to the level of individual functions. Once Turbopack performs a task it never does it again.Our team has taken the lessons from 10 years of Webpack, combined with the innovations in incremental computation from Turborepo and Google's Bazel, and created an architecture ready to support the coming decades of computing.\nTurbopack is currently in alpha. It is not yet ready for production use. We appreciate your support and feedback as we work to make it ready for everyone.","quickstart#Quickstart":"As of today, Turbopack can be used in Next.js v13. In the future we will be releasing a standalone CLI, plugin API, and support for other frameworks such as Svelte and Vue. For now, please follow these instructions to get started:\nCreate a Next.js v13 project with Turbopack:\n\n\nnpx create-next-app --example with-turbopack\n\nStart the Next.js development server (with Turbopack):\n\n\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm dev\n\n\nThe Next.js v13 development server is now powered by Turbopack! Startup and updates should both be near-instant. The larger the application, the larger the improvement will be.","next-steps#Next Steps":"Want to learn more about Turbopack? Here's a deep dive on what we think makes it special."}},"/sdk/docs/roadmap":{"title":"Roadmap","data":{"":"We've got big plans for Turbopack. Here's what we're aiming for in the future:","nextjs#Next.js":"Right now, Turbopack is being used as an opt-in feature in Next.js's dev server. This is helping to create an extremely fast experience in local development that scales to big projects.Next, we want to use Turbopack to power production builds with Next.js. We think that this will result in a big boost in performance, especially when integrated with remote caching.","svelte#Svelte":"We're planning to build a first-class integration with Svelte to let Turbopack power the next generation of SvelteKit applications.","other-frameworks#Other Frameworks":"We are in active discussions with other frameworks to bring Turbopack to their users. We're excited to see what we can build together!","remote-caching-and-replication#Remote Caching and Replication":"Turbopack is built from the ground up to take advantage of caching. Currently, this cache is stored in-memory only. This lets us optimize for our current use case - making the Next.js dev server fast.In the future, we plan to persist this cache to the file system, to speed up Turbopack between runs. This will work similarly to Turborepo's cache - but at a much more granular level. Turborepo can currently only cache the results of entire builds. Turbopack, however, can cache the results of individual functions within those builds - saving much more time over subsequent runs.Once persisting to the file system is working, we can build the next logical step: persisting to a remote cache. With Turborepo, we've already built remote caching on Vercel. In the future, you'll be able to share Turbopack's hyper-granular cache across your whole team, using the Vercel Remote Cache.","migration-for-webpack-users#Migration for Webpack users":"To learn more about our future plans for Webpack integration, check out our Migrating from Webpack page.","fusion-with-turborepo#Fusion with Turborepo":"We are currently migrating/rewriting Turborepo in Rust. In the future, Turborepo and Turbopack will merge into a single toolchain--Turbo--that can be used as either a bundler or a build system or both."}},"/sdk/docs/why-turbopack":{"title":"Why OpenBB SDK?","data":{"":"When we set out to create Turbopack, we wanted to solve a problem. We had been working on speed improvements for Next.js. We migrated away from several JS-based tools. Babel, gone. Terser, gone. Our next target was another JS-based tool, Webpack.Replacing it became our goal. But with what?A new generation of native-speed bundlers were emerging, like esbuild and swc. But after assessing the bundlers on the market, we decided to build our own. Why?","bundling-vs-native-esm#Bundling vs Native ESM":"Frameworks like Vite use a technique where they donâ€™t bundle application source code in development mode. Instead, they rely on the browserâ€™s native ES Modules system. This approach results in incredibly responsive updates since they only have to transform a single file.However, Vite can hit scaling issues with large applications made up of many modules. A flood of cascading network requests in the browser can lead to a relatively slow startup time. For the browser, itâ€™s faster if it can receive the code it needs in as few network requests as possible - even on a local server.Thatâ€™s why we decided that, like Webpack, we wanted Turbopack to bundle the code in the development server. Turbopack can do it much faster, especially for larger applications, because it is written in Rust and skips optimization work that is only necessary for production.","incremental-computation#Incremental Computation":"There are two ways to make a process faster: do less work or do work in parallel. We knew if we wanted to make the fastest bundler possible, weâ€™d need to pull hard on both levers.We decided to create a reusable Turbo build engine for distributed and incremental behavior. The Turbo engine works like a scheduler for function calls, allowing calls to functions to be parallelized across all available cores.The Turbo engine also caches the result of all the functions it schedules, meaning it never needs to do the same work twice. Put simply, it does the minimum work at maximum speed.","vite-and-esbuild#Vite and esbuild":"Other tools take a different attitude to â€˜doing less workâ€™. Vite minimizes work done by using Native ESM in development mode. We decided not to take this approach for the reasons listed above.Under the hood, Vite uses esbuild for many tasks. esbuild is a bundler - a superbly fast one. It doesnâ€™t force you to use native ESM. But we decided not to adopt esbuild for a few reasons.esbuildâ€™s code is hyper-optimized for one task - bundling fast. It doesnâ€™t have HMR, which we donâ€™t want to lose from our dev server.esbuild is an extremely fast bundler, but it doesnâ€™t do much caching. This means you will end up doing the same work again and again, even if that work is at the speed of native.Evan Wallace refers to esbuild as a proof-of-concept for the next generation of bundlers. We think heâ€™s right. We feel that a Rust-powered bundler with incremental computation could perform better at a larger scale than esbuild.","lazy-bundling#Lazy bundling":"Early versions of Next.js tried to bundle the entire web app in development mode. We quickly realized that this â€˜eagerâ€™ approach was less than optimal. Modern versions of Next.js bundle only the pages requested by the dev server. For instance, if you go to localhost:3000, itâ€™ll bundle only pages/index.jsx, and the modules it imports.This more â€˜lazyâ€™ approach (only bundling assets when absolutely necessary) is key for a fast dev server. Native ESM handles this without much magic - you request a module, which requests other modules. However, we wanted to build a bundler, for the reasons explained above.esbuild doesnâ€™t have a concept of â€˜lazyâ€™ bundling - itâ€™s all-or-nothing, unless you specifically target only certain entry points.Turbopackâ€™s development mode builds a minimal graph of your appâ€™s imports and exports based on received requests and only bundles the minimal code necessary. Learn more in the core concepts docs.This strategy makes Turbopack extremely fast when first starting up the dev server. We compute only the code necessary to render the page, then ship it to the browser in a single chunk. At large scale, this ends up being significantly faster than Native ESM.","summary#Summary":"We wanted to:\nBuild a bundler. Bundlers outperform Native ESM when working on large applications.\nUse incremental computation. The Turbo engine brings this into the core of Turbopackâ€™s architecture - maximizing speed and minimizing work done.\nOptimize our dev serverâ€™s startup time. For that, we build a lazy asset graph to compute only the assets requested.\n\nThatâ€™s why we chose to build Turbopack."}},"/sdk/docs/comparisons/turbopack-vs-vite":{"title":"OpenBB SDK vs yfinance","data":{"":"Vite is an incredibly fast (non-)bundler that the web development community is extremely excited about - and so are we. Vite has raised the bar for web development and shown us what is possible for the future of the Web. If we were going to build a bundler, it had to perform at least as good as the (already impressive) Vite to validate our efforts. We're proud to say that we achieved that.","speed#Speed":"Turbopack can outperform Vite on several key metrics.","dev-server-startup-time#Dev server startup time":"Vite is a non-bundler, which means it doesn't bundle your code at all. It sends each module directly to the browser. This means the browser does the hard work of handling dependencies between modules.On the surface, this seems like an unfair fight. Turbopack bundles your application, meaning that a lot more work needs doing before sending the code to the browser.But it turns out that Turbopack can handle this faster than the browser can. By pre-bundling, we can save a lot of time over Vite's Native ESM system. You can learn more about this in our Why Turbopack section.This means that Turbopack's dev server starts up much faster than Vite's. On a 1,000 module application, Vite takes  to start up. Turbopack starts up in  -  faster.In large applications, this differential stays consistent. In a 30,000 module application, Turbopack starts up  faster than Vite.","code-updates#Code updates":"Vite is extremely fast in development because of its speedy Fast Refresh capabilities. When you update a file, Vite uses its Native ESM system to to send the updated module to the browser - and performs a little bit of magic to integrate that into the existing module graph.In Turbopack, we discovered that for Fast Refresh, we don't really need to do bundling work at all. We can send updates in a similar style to Vite. In fact - a little bit more efficently: Turbopack sends changed modules directly through the WebSocket without doing any bundling at all.In a 1,000 module application, Turbopack can react to file changes  faster than Vite."}},"/sdk/docs/comparisons/turbopack-vs-webpack":{"title":"OpenBB SDK vs vnpy","data":{"":"Webpack has been downloaded over 3 billion times, making it today's most common JavaScript bundler. However, we found that we'd hit the limits of what it could do with its JavaScript-based architecture.We've built Turbopack as the successor of Webpack: much faster, but just as flexible and extensible.","speed#Speed":"Turbopack's incremental architecture outstrips Webpack's speed on several key metrics.","dev-server-startup-time#Dev server startup time":"The main problem we found with Webpack was development server startup time. If you end up importing a lot of modules in a certain page and open that page in your browser, the initial compile will take a few seconds. If you change routes in your development environment, you have to wait for a similar compile again for your new page.We designed Turbopack to be as lazy as possible, only doing work when it's requested. In a dev server, this means on incoming requests we do exactly the work the user asked for. No more unnecessary bundling of on demand loaded code before the user needs it. You can learn more in our core concepts docs.This means that Turbopack's dev server starts up much faster than Webpack. Next.js 12, which uses Webpack under the hood, can start up a build server on a 1,000 module application in . Turbopack starts up in  -  faster.","code-updates#Code updates":"As we continued to optimize Webpack, we found a performance ceiling on how much faster we could make Fast Refresh. With around 2,000 components, the best number we could produce was 500ms. This mark was a tremendous feat in Next.js 12. Previously, that process would have taken around 10 seconds.With Turbopack, we achieved the goal we were aiming for: Fast Refresh performance that stays near-constant, no matter your application size. Instead of scaling with your application size, it scales based on the size of the changes made.In a 1,000 module application, Turbopack can react to file changes  faster than Webpack. In a 30,000 module application, this is  faster.","extensibility#Extensibility":"Webpack has an extraordinary collection of plugins to customize its behavior. Composing plugins lets you create custom toolchains which can support a huge variety of bundler features.In its alpha state, Turbopack cannot currently be configured with plugins. In the future, we plan to make Turbopack just as extensible as Webpack - though likely with an altered API."}},"/sdk/docs/features/stocks":{"title":"Stocks","data":{"":"Turbopack supports TypeScript out of the box. This means you can import .ts files with Turbopack. We support all of TypeScript's feature set.Thanks to our JSX support, you can also import .tsx files too.","resolving-paths-and-baseurl#Resolving paths and baseUrl":"In TypeScript, you can use the paths property of tsconfig.json to let you import files from custom paths.\n{\n\"compilerOptions\": {\n\"baseUrl\": \"src\",\n\"paths\": {\n\"app/*\": [\"app/*\"],\n\"config/*\": [\"app/_config/*\"],\n\"shared/*\": [\"app/_shared/*\"],\n},\n}\nThis would let you import directly from app/* without needing to do a relative import:\n- import { add } from '../../../../../math';\n+ import { add } from 'app/math';\n\nadd();\nTurbopack reads the paths and baseUrl in tsconfig.json in order to resolve these paths, just like Next.js does.This means you only need to configure your absolute paths in one place.","type-checking#Type Checking":"Turbopack does not perform type checks on your application. We use SWC to compile TypeScript code, which also does not perform type checks.This means that in order to run your type checks, you'll need a sidecar process running tsc --watch. Or, you can rely on your IDE's TypeScript integration."}},"/sdk/docs/getting-started/add-to-project":{"title":"Installation","data":{"":"Turborepo can be used in any project to speed up the execution of scripts in your package.json.After you install turbo, you'll be able to run all your package.json tasks from turbo instead of your package manager.By configuring your turbo.json correctly, you'll notice how caching helps your tasks run a lot faster.","quickstart#Quickstart":"If you don't have one already, create a new application:\n\n\n\n\nnpx create-next-app@latest\n\n\n\nnpm create vite@latest\n\n\n\nInstall turbo:\n\n\n\n\nnpm install turbo --save-dev\n\n\n\nyarn add turbo --dev\n\n\n\npnpm install turbo --save-dev\n\n\n\nAdd a turbo.json file at the base of your new repository:\n\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nSome Vite starters ship with a package.json that looks like this:\n{\n\"scripts\": {\n\"build\": \"tsc && vite build\"\n}\n}\nWe recommend splitting these into a lint and build script.\n{\n\"scripts\": {\n\"build\": \"vite build\",\n\"lint\": \"tsc\"\n}\n}\nThis means that Turbo can schedule them separately.\n\n\nTry running build and lint with turbo:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nThis runs build and lint at the same time.\nWithout making any changes to the code, try running build and lint again:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nYou should see terminal output like this:\nTasks:    2 successful, 2 total\nCached:    2 cached, 2 total\nTime:    185ms >>> FULL TURBO\nCongratulations - you just completed a build and lint in under 200ms.To learn how this is possible, check out our core concepts docs.\nTry running dev with turbo:\n\n\n\n\nnpx turbo dev\n\n\n\nyarn turbo dev\n\n\n\npnpm turbo dev\n\n\nYou'll notice that your dev script starts up. You can use turbo to run any script in your package.json."}},"/sdk/docs/getting-started/existing-monorepo":{"title":"First commands","data":{"":"turbo works with Yarn, npm, and pnpm on the following operating systems:\nmacOS darwin 64-bit (Intel), ARM 64-bit (Apple Silicon)\nLinux 32-bit, 64-bit, ARM, ARM 64-bit, MIPS 64-bit Little Endian, PowerPC 64-bit Little Endian, IBM Z 64-bit Big Endian\nWindows 32-bit, 64-bit, ARM 64-bit\nFreeBSD 64-bit, ARM 64-bit\nNetBSD AMD64\nAndroid ARM 64-bit","configure-workspaces#Configure workspaces":"turbo is built on top of Workspaces, a way of managing multiple packages from within a single monorepo package. Turborepo is compatible with the workspace implementations from all package managers. For more information on managing your Turborepo workspaces, see the Workspaces documentation.You can configure workspaces any way you want, but a common folder structure example is keeping applications in the /apps folder and packages in the /packages folder. The configuration of these folders is different for each package manager.\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your packages in pnpm-workspace.yaml.\npackages:\n- \"packages/*\"\n- \"apps/*\"\n\n\nAfter configuring your workspaces, re-run your package manager's install command.\nNote: Nested workspaces are not supported. As package names are required to be\nunique, moving each package to be a child of the monorepo's root package\nshould meet your needs.","install-turbo#Install turbo":"Add turbo as a development dependency at the root of your monorepo.\n\n\nnpm install turbo -D\n\n\n\nyarn add turbo -DW\n\n\n\npnpm add turbo -Dw\n\n\nThe turbo package is a shell script that will install the proper turbo-<os>-<arch> package for your operating system and architecture.\nNote: Linux builds of turbo link against glibc. For Alpine Docker environments, you will need to ensure libc6-compat is installed as well, via RUN apk add --no-cache libc6-compat","create-turbojson#Create turbo.json":"In the root of your monorepo, create an empty file named turbo.json. This will hold the configuration for Turborepo.\n{\n\"$schema\": \"https://turbo.build/schema.json\"\n}","create-a-pipeline#Create a pipeline":"To define your monorepo's task dependency graph, use the pipeline key in the turbo.json configuration file at the root of monorepo. turbo interprets this configuration to optimally schedule, execute, and cache the outputs of each of the package.json scripts defined in your workspaces.Each key in the pipeline object is the name of a package.json script that can be executed by turbo run. You can specify its dependencies with the dependsOn key inside it as well as some other options related to caching. For more information on configuring your pipeline, see the Pipelines documentation.Workspaces that do not have the specified script defined in their package.json's list of scripts will be ignored by turbo.\n{\n\"$schema\": \"https://turbo.build/schema.json\",\n\"pipeline\": {\n\"build\": {\n// A package's `build` script depends on that package's\n// dependencies and devDependencies\n// `build` tasks  being completed first\n// (the `^` symbol signifies `upstream`).\n\"dependsOn\": [\"^build\"],\n// note: output globs are relative to each package's `package.json`\n// (and not the monorepo root)\n\"outputs\": [\".next/**\"]\n},\n\"test\": {\n// A package's `test` script depends on that package's\n// own `build` script being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [],\n// A package's `test` script should only be rerun when\n// either a `.tsx` or `.ts` file has changed in `src` or `test` folders.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\", \"test/**/*.tsx\"]\n},\n\"lint\": {\n// A package's `lint` script has no dependencies and\n// can be run whenever. It also has no filesystem outputs.\n\"outputs\": []\n},\n\"deploy\": {\n// A package's `deploy` script depends on the `build`,\n// `test`, and `lint` scripts of the same package\n// being completed. It also has no filesystem outputs.\n\"dependsOn\": [\"build\", \"test\", \"lint\"],\n\"outputs\": []\n}\n}\n}\nThe rough execution order for a given package is based on the dependsOn keys:\nbuild once its upstream dependencies have run their build commands\ntest once its own build command is finished and has no filesystem outputs (just logs) within a package\nlint runs in an arbitrary order as it has no upstream dependencies\ndeploy once its own build, test, and lint commands have finished.\n\nAfter execution, the full pipline can run:\nnpx turbo run build test lint deploy\nturbo will then schedule the execution of each task(s) to optimize usage of the machine's resources.","edit-gitignore#Edit .gitignore":"Add .turbo to your .gitignore file. The CLI uses these folders for logs and certain task outputs.\n+ .turbo\nMake sure that your task artifacts, the files and folders you want cached, are also included in your .gitignore.\n+ build/**\n+ dist/**\n+ .next/**\nRe-run your npm client's install command to check your configuration.","create-packagejson-scripts#Create package.json scripts":"Add or update scripts in your monorepo's root package.json file and have them delegate to turbo.\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\",\n\"lint\": \"turbo run lint\",\n\"dev\": \"turbo run dev\"\n}\n}","build-your-monorepo#Build your monorepo":"npm run build\n\n\n\nyarn build\n\n\n\npnpm build\n\n\nDepending on your monorepo setup, some artifacts might already be caching properly. In the next sections, we'll show how turbo works, how scope works, and then how to get caching working after that.","configure-remote-caching#Configure Remote Caching":"A major key ðŸ”‘ to Turborepo's speed is that it is both lazy and efficientâ€”it does the least amount of work possible and it tries to never redo work that's already been done before.At the moment, Turborepo caches your tasks on your local filesystem (i.e. \"single-player mode,\" if you will). However, what if there was a way to take advantage of the computational work done by your teammates or your CI (i.e. \"co-op multiplayer mode\")? What if there was a way to teleport and share a single cache across machines? Almost like a \"Dropbox\" for your Turborepo cache.\nRemote Caching has entered the chat.\nTurborepo can use a technique known as Remote Caching to share cache artifacts across machines for an additional speed boost.\nRemote Caching is a powerful feature of Turborepo, but with great power comes\ngreat responsibility. Make sure you are caching correctly first and double\ncheck handling of environment variables. Please also remember Turborepo treats\nlogs as artifacts, so be aware of what you are printing to the console.","using-remote-caching-for-local-development#Using Remote Caching for Local development":"Turborepo uses Vercel as its default remote caching provider. If you want to link your local turborepo to your Remote Cache you can authenticate the Turborepo CLI with your Vercel account:\nnpx turbo login\nThen, link your turborepo to your remote cache:\nnpx turbo link\nOnce enabled, make some changes to a package or application you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache. To verify that this worked, delete your local Turborepo cache:\nrm -rf ./node_modules/.cache/turbo\nRun the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you.\nNote: When connecting to an sso-enabled Vercel team, you must provide your\nTeam slug as an argument to npx turbo login.\n\nnpx turbo login --sso-team=<team-slug>","next-steps#Next Steps":"You're now up and running with Turborepo, but there are still a few things to do:\nUnderstand how Turborepo caching works\nCorrectly handle environment variables\nLearn to orchestrate task running with pipelines\nEfficiently filter package tasks\nConfigure Turborepo with your CI provider"}},"/sdk/docs/getting-started/create-new":{"title":"Import","data":{"":"","quickstart#Quickstart":"To create a new monorepo, use our create-turbo npm package:\nnpx create-turbo@latest\nYou can also clone a Turborepo starter repository to get a head start on your monorepo. To see Turborepo examples and starters, see the Turborepo examples directory on GitHub.","full-tutorial#Full tutorial":"This tutorial will walk you through using the Turborepo basic example. By the end, you'll feel confident with using turbo, and know all the basic functionality.\nDuring this tutorial, some lines of code are omitted from the code samples. For instance, when showing a package.json we won't show all of the keys - only the ones that matter.","1-running-create-turbo#1. Running create-turbo":"First, run:\nnpx create-turbo@latest\nThis installs the create-turbo CLI, and runs it. You'll be asked several questions:","where-would-you-like-to-create-your-turborepo#Where would you like to create your turborepo?":"Choose anywhere you like. The default is ./my-turborepo.","which-package-manager-do-you-want-to-use#Which package manager do you want to use?":"Turborepo doesn't handle installing packages, so you'll need to choose either:\nnpm\npnpm\nyarn\n\nIf you're not sure, we recommend choosing pnpm. If you don't have it installed, cancel create-turbo (via ctrl-C) and take a look at the installation instructions.","installation#Installation":"Once you've picked a package manager, create-turbo will create a bunch of new files inside the folder name you picked. It'll also install all the dependencies that come with the basic example by default.","2-exploring-your-new-repo#2. Exploring your new repo":"You might have noticed something in the terminal. create-turbo gave you a description of all of the things it was adding.\n>>> Creating a new turborepo with the following:\n\n- apps/web: Next.js with TypeScript\n- apps/docs: Next.js with TypeScript\n- packages/ui: Shared React component library\n- packages/eslint-config-custom: Shared configuration (ESLint)\n- packages/tsconfig: Shared TypeScript `tsconfig.json`\nEach of these is a workspace - a folder containing a package.json. Each workspace can declare its own dependencies, run its own scripts, and export code for other workspaces to use.Open the root folder - ./my-turborepo - in your favourite code editor.","understanding-packagesui#Understanding packages/ui":"First, open ./packages/ui/package.json. You'll notice that the package's name is \"name\": \"ui\" - right at the top of the file.Next, open ./apps/web/package.json. You'll notice that this package's name is \"name\": \"web\". But also - take a look in its dependencies.You'll see that \"web\" depends on a package called \"ui\". If you're using pnpm, you'll see it's declared like this:\n{\n\"dependencies\": {\n\"ui\": \"workspace:*\"\n}\n}\nThis means that our web app depends on our local ui package.If you look inside apps/docs/package.json, you'll see the same thing. Both web and docs depend on ui - a shared component library.This pattern of sharing code across applications is extremely common in monorepos - and means that multiple apps can share a single design system.","understanding-imports-and-exports#Understanding imports and exports":"Take a look inside ./apps/docs/pages/index.tsx. Both docs and web are Next.js applications, and they both use the ui library in a similar way:\nimport { Button } from \"ui\";\n//       ^^^^^^         ^^\n\nexport default function Docs() {\nreturn (\n<div>\n<h1>Docs</h1>\n<Button />\n</div>\n);\n}\nThey're importing Button directly from a dependency called ui! How does that work? Where is Button coming from?Open packages/ui/package.json. You'll notice these two attributes:\n{\n\"main\": \"./index.tsx\",\n\"types\": \"./index.tsx\"\n}\nWhen workspaces import from ui, main tells them where to access the code they're importing. types tells them where the TypeScript types are located.So, let's look inside packages/ui/index.tsx:\nimport * as React from \"react\";\nexport * from \"./Button\";\nEverything inside this file will be able to be used by workspaces that depend on ui.index.tsx is exporting everything from a file called ./Button, so let's go there:\nimport * as React from \"react\";\n\nexport const Button = () => {\nreturn <button>Boop</button>;\n};\nWe've found our button! Any changes we make in this file will be shared across web and docs. Pretty cool!\nTry experimenting with exporting a different function from this file. Perhaps add(a, b) for adding two numbers together.This can then be imported by web and docs.","understanding-tsconfig#Understanding tsconfig":"We have two more workspaces to look at, tsconfig and eslint-config-custom. Each of these allow for shared configuration across the monorepo. Let's look in tsconfig:\n{\n\"name\": \"tsconfig\",\n\"files\": [\"base.json\", \"nextjs.json\", \"react-library.json\"]\n}\nHere, we specify three files to be exported, inside files. Packages which depend on tsconfig can then import them directly.For instance, packages/ui depends on tsconfig:\n{\n\"devDependencies\": {\n\"tsconfig\": \"workspace:*\"\n}\n}\nAnd inside its tsconfig.json file, it imports it using extends:\n{\n\"extends\": \"tsconfig/react-library.json\"\n}\nThis pattern allows for a monorepo to share a single tsconfig.json across all its workspaces, reducing code duplication.","understanding-eslint-config-custom#Understanding eslint-config-custom":"Our final workspace is eslint-config-custom.You'll notice that this is named slightly differently to the other workspaces. It's not as concise as ui or tsconfig. Let's take a look inside .eslintrc.js in the root of the monorepo to figure out why.\nmodule.exports = {\n// This tells ESLint to load the config from the workspace `eslint-config-custom`\nextends: [\"custom\"],\n};\nESLint resolves configuration files by looking for workspaces with the name eslint-config-*. This lets us write extends: ['custom'] and have ESLint find our local workspace.But why is this in the root of the monorepo?The way ESLint finds its configuration file is by looking at the closest .eslintrc.js. If it can't find one in the current directory, it'll look in the directory above until it finds one.So that means that if we're working on code inside packages/ui (which doesn't have a .eslintrc.js) it'll refer to the root instead.Apps that do have an .eslintrc.js can refer to custom in the same way. For instance, in docs:\nmodule.exports = {\nroot: true,\nextends: [\"custom\"],\n};\nJust like tsconfig, eslint-config-custom lets us share ESLint configs across our entire monorepo, keeping things consistent no matter what project you're working on.","summary#Summary":"It's important to understand the dependencies between these workspaces. Let's map them out:\nweb - depends on ui, tsconfig and eslint-config-custom\ndocs - depends on ui, tsconfig and eslint-config-custom\nui - depends on tsconfig and eslint-config-custom\ntsconfig - no dependencies\neslint-config-custom - no dependencies\n\nNote that the Turborepo CLI is not responsible for managing these dependencies. All of the things above are handled by the package manager you chose (npm, pnpm or yarn).","3-understanding-turbojson#3. Understanding turbo.json":"We now understand our repository and its dependencies. How does Turborepo help?Turborepo helps by making running tasks simpler and much more efficient.Let's take a look inside our root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev\",\n\"lint\": \"turbo run lint\"\n}\n}\nWe've got three tasks specified here in scripts which use turbo run. You'll notice that each of them is specified in turbo.json:\n{\n\"pipeline\": {\n\"build\": {\n//   ^^^^^\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\"dist/**\", \".next/**\"]\n},\n\"lint\": {\n//   ^^^^\n\"outputs\": []\n},\n\"dev\": {\n//   ^^^\n\"cache\": false\n}\n}\n}\nWhat we're seeing here is that we've registered three tasks with turbo - lint, dev and build. Every task that's registered inside turbo.json can be run with turbo run <task>.To see this in action, let's add a script to the root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev --parallel\",\n\"lint\": \"turbo run lint\",\n+   \"hello\": \"turbo run hello\"\n}\n}\nNow, let's run hello.\n\n\nnpm run hello\n\n\n\nyarn hello\n\n\n\npnpm run hello\n\n\nYou'll see this error in the console:\ntask `hello` not found in turbo `pipeline` in \"turbo.json\".\nAre you sure you added it?\nThat's worth remembering - in order for turbo to run a task, it must be in turbo.json.Let's investigate the scripts we already have in place.","4-linting-with-turborepo#4. Linting with Turborepo":"Try running our lint script:\n\n\nnpm run lint\n\n\n\nyarn lint\n\n\n\npnpm run lint\n\n\nYou'll notice several things happen in the terminal.\nSeveral scripts will be run at the same time, each prefixed with either docs:lint, ui:lint or web:lint.\nThey'll each succeed, and you'll see 3 successful in the terminal.\nYou'll also see 0 cached, 3 total. We'll cover what this means later.\n\nThe scripts that each run come from each workspace's package.json. Each workspace can optionally specify its own lint script:\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"eslint *.ts*\"\n}\n}\nWhen we run turbo run lint, Turborepo looks at each lint script in each workspace and runs it. For more details, see our pipelines docs.","using-the-cache#Using the cache":"Let's run our lint script one more time. You'll notice a few new things appear in the terminal:\ncache hit, replaying output appears for docs:lint, web:lint and ui:lint.\nYou'll see 3 cached, 3 total.\nThe total runtime should be under 100ms, and >>> FULL TURBO appears.\n\nSomething interesting just happened. Turborepo realised that our code hadn't changed since the last time we ran the lint script.It had saved the logs from the previous run, so it just replayed them.Let's try changing some code to see what happens. Make a change to a file inside apps/docs:\nimport { Button } from \"ui\";\n\nexport default function Docs() {\nreturn (\n<div>\n-     <h1>Docs</h1>\n+     <h1>My great docs</h1>\n<Button />\n</div>\n);\n}\nNow, run the lint script again. You'll notice that:\ndocs:lint has a comment saying cache miss, executing. This means that docs is running its linting.\n2 cached, 3 total appears at the bottom.\n\nThis means that the results of our previous tasks were still cached. Only the lint script inside docs actually ran - again, speeding things up. To learn more, check out our caching docs.","5-building-with-turborepo#5. Building with Turborepo":"Let's try running our build script:\n\n\nnpm run build\n\n\n\nyarn build\n\n\n\npnpm run build\n\n\nYou'll see similar outputs to when we ran our lint script. Only apps/docs and apps/web specify a build script in their package.json, so only those are run.Take a look inside build in turbo.json. There's some interesting config there.\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n}\n}\n}\nYou'll notice that some outputs have been specified. Declaring outputs will mean that when turbo finishes running your task, it'll save the output you specify in its cache.Both apps/docs and apps/web are Next.js apps, and they output builds to the ./.next folder.Let's try something. Delete the apps/docs/.next build folder.Run the build script again. You'll notice:\nWe hit FULL TURBO - the builds complete in under 100ms.\nThe .next folder re-appears!\n\nTurborepo cached the result of our previous build. When we ran the build command again, it restored the entire .next/** folder from the cache. To learn more, check out our docs on cache outputs.","6-running-dev-scripts#6. Running dev scripts":"Let's now try running dev.\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm run dev\n\n\nYou'll notice some information in the terminal:\nOnly two scripts will execute - docs:dev and web:dev. These are the only two workspaces which specify dev.\nBoth dev scripts are run simultaneously, starting your Next.js apps on ports 3000 and 3001.\nIn the terminal, you'll see cache bypass, force executing.\n\nTry quitting out of the script, and re-running it. You'll notice we don't go FULL TURBO. Why is that?Take a look at turbo.json:\n{\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}\nInside dev, we've specified \"cache\": false. This means we're telling Turborepo not to cache the results of the dev script. dev runs a persistent dev server and produces no outputs, so caching it makes no sense. Learn more about in our docs on turning off caching.","running-dev-on-only-one-workspace-at-a-time#Running dev on only one workspace at a time":"By default, turbo run dev will run dev on all workspaces at once. But sometimes, we might only want to choose one workspace.To handle this, we can add a --filter flag to our command. This --filter gets passed to the turbo CLI.\n\n\nnpm run dev -- --filter docs\n\n\n\nyarn dev --filter docs\n\n\n\npnpm run dev --filter docs\n\n\nYou'll notice that it now only runs docs:dev. Learn more about filtering workspaces from our docs.","summary-1#Summary":"Well done! You've learned all about your new monorepo, and how Turborepo makes handling your tasks easier.","next-steps#Next steps":"Need to add more tasks? Learn more about using pipelines\nWant to speed up your CI? Set up remote caching.\nWant some inspiration? Take a look at our directory of examples"}},"/terminal":{"data":{"":""}},"/terminal/docs/core-concepts":{"title":"Core Concepts","data":{"":"Letâ€™s dive deep into the internals of Turbopack to figure out why itâ€™s so fast.","the-turbo-engine#The Turbo engine":"Turbopack is so fast because itâ€™s built on a reusable library for Rust which enables incremental computation known as the Turbo engine. Hereâ€™s how it works:","function-level-caching#Function-level caching":"In a Turbo engine-powered program, you can mark certain functions as â€˜to be rememberedâ€™. When these functions are called, the Turbo engine will remember what they were called with, and what they returned. Itâ€™ll then save it in an in-memory cache.Hereâ€™s a simplified example of what this might look like in a bundler:\n\nWe start with calling readFile on two files, api.ts and sdk.ts. We then bundle those files, concat them together, and end up with the fullBundle at the end. The results of all of those function calls get saved in the cache for later.Letâ€™s imagine that weâ€™re running on a dev server. You save the sdk.ts file on your machine. Turbopack receives the file system event, and knows it needs to recompute readFile(\"sdk.ts\"):\n\nSince the result of sdk.ts has changed, we need to bundle it again, which then needs to be concatenated again.Crucially, api.ts hasnâ€™t changed. We read its result from the cache and pass that to concat instead. So we save time by not reading it and re-bundling it again.Now imagine this in a real bundler, with thousands of files to read and transformations to execute. The mental model is the same. You can save enormous amounts of work by remembering the result of function calls and not re-doing work thatâ€™s been done before.","the-cache#The cache":"The Turbo engine currently stores its cache in memory. This means the cache will last as long as the process running it - which works well for a dev server. When you run next dev --turbo in Next v13, youâ€™ll start a cache with the Turbo engine. When you cancel your dev server, the cache gets cleared.In the future, weâ€™re planning to persist this cache - either to the filesystem, or to a remote cache like Turborepoâ€™s. This will mean that Turbopack could remember work done across runs and machines.","how-does-it-help#How does it help?":"This approach makes Turbopack extremely fast at computing incremental updates to your apps. This optimizes Turbopack for handling updates in development, meaning your dev server will always respond snappily to changes.In the future, a persistent cache will open the door to much faster production builds. By remembering work done across runs, new production builds could only rebuild changed files - potentially leading to enormous time savings.","compiling-by-request#Compiling by Request":"The Turbo engine helps provide extremely fast updates on your dev server, but thereâ€™s another important metric to consider - startup time. The faster your dev server can start running, the faster you can get to work.There are two ways to make a process faster - work faster, or do less work. For starting up a dev server, the way to do less work is to compile only the code thatâ€™s needed to get started.","page-level-compilation#Page-level compilation":"Versions of Next.js from 2-3 years ago used to compile the entire application before showing your dev server. In Next.js [11], we began compiling only the code on the page you requested.Thatâ€™s better, but itâ€™s not perfect. When you navigate to /users, weâ€™ll bundle all the client and server modules, dynamic-imported modules, and referenced CSS and images. That means if a large part of your page is hidden from view, or hidden behind tabs, weâ€™ll still compile it anyway.","request-level-compilation#Request-level compilation":"Turbopack is smart enough to compile only the code you request. That means if a browser requests HTML, we compile only the HTML - not anything that is referenced by the HTML.If a browser wants some CSS, weâ€™ll compile only that - without compiling referenced images. Got a big charting library behind next/dynamic? Doesnâ€™t compile it until the tab showing the chart is shown. Turbopack even knows to not compile source maps unless your Chrome DevTools are open.If we were to use native ESM, weâ€™d get similar behavior. Except that Native ESM produces a lot of requests to the server, as discussed in our Why Turbopack section. With request-level compilation, we get to both reduce the number of requests and use native speed to compile them. As you can see in our benchmarks, this provides significant performance improvements."}},"/terminal/docs/features":{"title":"Features","data":{"":"The practice of building web applications is enormously diverse. In CSS alone, you have SCSS, Less, CSS Modules, PostCSS, and hundreds of other libraries. Frameworks like React, Vue and Svelte require custom setups.When building a bundler, we needed to consider which features would be:\nBuilt-in: they work out of the box, no config required\nAvailable via plugins: usually installed from a registry and configured\nUnavailable: not available at all\n\nTurbopack is in alpha, so very few of these decisions are set in stone. In its current state, Turbopack cannot yet be configured - so plugins are not available yet.Let's discuss which features are available out-of-the-box, in Turbopack's default configuration. We'll also touch on features which will be configurable via plugins."}},"/terminal/docs":{"title":"Quickstart","data":{"":"Turbopack is an incremental bundler optimized for JavaScript and TypeScript, written in Rust by the creators of Webpack and Next.js at Vercel.On large applications Turbopack updates 10x faster than Vite and 700x faster than Webpack. For the biggest applications the difference grows even more stark with updates up to 20x faster than Vite.The secret to Turbopack's performance is twofold: highly optimized machine code and a low-level incremental computation engine that enables caching down to the level of individual functions. Once Turbopack performs a task it never does it again.Our team has taken the lessons from 10 years of Webpack, combined with the innovations in incremental computation from Turborepo and Google's Bazel, and created an architecture ready to support the coming decades of computing.\nTurbopack is currently in alpha. It is not yet ready for production use. We appreciate your support and feedback as we work to make it ready for everyone.","quickstart#Quickstart":"As of today, Turbopack can be used in Next.js v13. In the future we will be releasing a standalone CLI, plugin API, and support for other frameworks such as Svelte and Vue. For now, please follow these instructions to get started:\nCreate a Next.js v13 project with Turbopack:\n\n\nnpx create-next-app --example with-turbopack\n\nStart the Next.js development server (with Turbopack):\n\n\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm dev\n\n\nThe Next.js v13 development server is now powered by Turbopack! Startup and updates should both be near-instant. The larger the application, the larger the improvement will be.","next-steps#Next Steps":"Want to learn more about Turbopack? Here's a deep dive on what we think makes it special."}},"/terminal/docs/roadmap":{"title":"Roadmap","data":{"":"We've got big plans for Turbopack. Here's what we're aiming for in the future:","nextjs#Next.js":"Right now, Turbopack is being used as an opt-in feature in Next.js's dev server. This is helping to create an extremely fast experience in local development that scales to big projects.Next, we want to use Turbopack to power production builds with Next.js. We think that this will result in a big boost in performance, especially when integrated with remote caching.","svelte#Svelte":"We're planning to build a first-class integration with Svelte to let Turbopack power the next generation of SvelteKit applications.","other-frameworks#Other Frameworks":"We are in active discussions with other frameworks to bring Turbopack to their users. We're excited to see what we can build together!","remote-caching-and-replication#Remote Caching and Replication":"Turbopack is built from the ground up to take advantage of caching. Currently, this cache is stored in-memory only. This lets us optimize for our current use case - making the Next.js dev server fast.In the future, we plan to persist this cache to the file system, to speed up Turbopack between runs. This will work similarly to Turborepo's cache - but at a much more granular level. Turborepo can currently only cache the results of entire builds. Turbopack, however, can cache the results of individual functions within those builds - saving much more time over subsequent runs.Once persisting to the file system is working, we can build the next logical step: persisting to a remote cache. With Turborepo, we've already built remote caching on Vercel. In the future, you'll be able to share Turbopack's hyper-granular cache across your whole team, using the Vercel Remote Cache.","migration-for-webpack-users#Migration for Webpack users":"To learn more about our future plans for Webpack integration, check out our Migrating from Webpack page.","fusion-with-turborepo#Fusion with Turborepo":"We are currently migrating/rewriting Turborepo in Rust. In the future, Turborepo and Turbopack will merge into a single toolchain--Turbo--that can be used as either a bundler or a build system or both."}},"/terminal/docs/why-turbopack":{"title":"Why OpenBB Terminal?","data":{"":"When we set out to create Turbopack, we wanted to solve a problem. We had been working on speed improvements for Next.js. We migrated away from several JS-based tools. Babel, gone. Terser, gone. Our next target was another JS-based tool, Webpack.Replacing it became our goal. But with what?A new generation of native-speed bundlers were emerging, like esbuild and swc. But after assessing the bundlers on the market, we decided to build our own. Why?","bundling-vs-native-esm#Bundling vs Native ESM":"Frameworks like Vite use a technique where they donâ€™t bundle application source code in development mode. Instead, they rely on the browserâ€™s native ES Modules system. This approach results in incredibly responsive updates since they only have to transform a single file.However, Vite can hit scaling issues with large applications made up of many modules. A flood of cascading network requests in the browser can lead to a relatively slow startup time. For the browser, itâ€™s faster if it can receive the code it needs in as few network requests as possible - even on a local server.Thatâ€™s why we decided that, like Webpack, we wanted Turbopack to bundle the code in the development server. Turbopack can do it much faster, especially for larger applications, because it is written in Rust and skips optimization work that is only necessary for production.","incremental-computation#Incremental Computation":"There are two ways to make a process faster: do less work or do work in parallel. We knew if we wanted to make the fastest bundler possible, weâ€™d need to pull hard on both levers.We decided to create a reusable Turbo build engine for distributed and incremental behavior. The Turbo engine works like a scheduler for function calls, allowing calls to functions to be parallelized across all available cores.The Turbo engine also caches the result of all the functions it schedules, meaning it never needs to do the same work twice. Put simply, it does the minimum work at maximum speed.","vite-and-esbuild#Vite and esbuild":"Other tools take a different attitude to â€˜doing less workâ€™. Vite minimizes work done by using Native ESM in development mode. We decided not to take this approach for the reasons listed above.Under the hood, Vite uses esbuild for many tasks. esbuild is a bundler - a superbly fast one. It doesnâ€™t force you to use native ESM. But we decided not to adopt esbuild for a few reasons.esbuildâ€™s code is hyper-optimized for one task - bundling fast. It doesnâ€™t have HMR, which we donâ€™t want to lose from our dev server.esbuild is an extremely fast bundler, but it doesnâ€™t do much caching. This means you will end up doing the same work again and again, even if that work is at the speed of native.Evan Wallace refers to esbuild as a proof-of-concept for the next generation of bundlers. We think heâ€™s right. We feel that a Rust-powered bundler with incremental computation could perform better at a larger scale than esbuild.","lazy-bundling#Lazy bundling":"Early versions of Next.js tried to bundle the entire web app in development mode. We quickly realized that this â€˜eagerâ€™ approach was less than optimal. Modern versions of Next.js bundle only the pages requested by the dev server. For instance, if you go to localhost:3000, itâ€™ll bundle only pages/index.jsx, and the modules it imports.This more â€˜lazyâ€™ approach (only bundling assets when absolutely necessary) is key for a fast dev server. Native ESM handles this without much magic - you request a module, which requests other modules. However, we wanted to build a bundler, for the reasons explained above.esbuild doesnâ€™t have a concept of â€˜lazyâ€™ bundling - itâ€™s all-or-nothing, unless you specifically target only certain entry points.Turbopackâ€™s development mode builds a minimal graph of your appâ€™s imports and exports based on received requests and only bundles the minimal code necessary. Learn more in the core concepts docs.This strategy makes Turbopack extremely fast when first starting up the dev server. We compute only the code necessary to render the page, then ship it to the browser in a single chunk. At large scale, this ends up being significantly faster than Native ESM.","summary#Summary":"We wanted to:\nBuild a bundler. Bundlers outperform Native ESM when working on large applications.\nUse incremental computation. The Turbo engine brings this into the core of Turbopackâ€™s architecture - maximizing speed and minimizing work done.\nOptimize our dev serverâ€™s startup time. For that, we build a lazy asset graph to compute only the assets requested.\n\nThatâ€™s why we chose to build Turbopack."}},"/terminal/docs/comparisons/turbopack-vs-vite":{"title":"OpenBB Terminal vs Bloomberg Terminal","data":{"":"Vite is an incredibly fast (non-)bundler that the web development community is extremely excited about - and so are we. Vite has raised the bar for web development and shown us what is possible for the future of the Web. If we were going to build a bundler, it had to perform at least as good as the (already impressive) Vite to validate our efforts. We're proud to say that we achieved that.","speed#Speed":"Turbopack can outperform Vite on several key metrics.","dev-server-startup-time#Dev server startup time":"Vite is a non-bundler, which means it doesn't bundle your code at all. It sends each module directly to the browser. This means the browser does the hard work of handling dependencies between modules.On the surface, this seems like an unfair fight. Turbopack bundles your application, meaning that a lot more work needs doing before sending the code to the browser.But it turns out that Turbopack can handle this faster than the browser can. By pre-bundling, we can save a lot of time over Vite's Native ESM system. You can learn more about this in our Why Turbopack section.This means that Turbopack's dev server starts up much faster than Vite's. On a 1,000 module application, Vite takes  to start up. Turbopack starts up in  -  faster.In large applications, this differential stays consistent. In a 30,000 module application, Turbopack starts up  faster than Vite.","code-updates#Code updates":"Vite is extremely fast in development because of its speedy Fast Refresh capabilities. When you update a file, Vite uses its Native ESM system to to send the updated module to the browser - and performs a little bit of magic to integrate that into the existing module graph.In Turbopack, we discovered that for Fast Refresh, we don't really need to do bundling work at all. We can send updates in a similar style to Vite. In fact - a little bit more efficently: Turbopack sends changed modules directly through the WebSocket without doing any bundling at all.In a 1,000 module application, Turbopack can react to file changes  faster than Vite."}},"/terminal/docs/comparisons/turbopack-vs-webpack":{"title":"OpenBB Terminal vs Yahoo Finance","data":{"":"Webpack has been downloaded over 3 billion times, making it today's most common JavaScript bundler. However, we found that we'd hit the limits of what it could do with its JavaScript-based architecture.We've built Turbopack as the successor of Webpack: much faster, but just as flexible and extensible.","speed#Speed":"Turbopack's incremental architecture outstrips Webpack's speed on several key metrics.","dev-server-startup-time#Dev server startup time":"The main problem we found with Webpack was development server startup time. If you end up importing a lot of modules in a certain page and open that page in your browser, the initial compile will take a few seconds. If you change routes in your development environment, you have to wait for a similar compile again for your new page.We designed Turbopack to be as lazy as possible, only doing work when it's requested. In a dev server, this means on incoming requests we do exactly the work the user asked for. No more unnecessary bundling of on demand loaded code before the user needs it. You can learn more in our core concepts docs.This means that Turbopack's dev server starts up much faster than Webpack. Next.js 12, which uses Webpack under the hood, can start up a build server on a 1,000 module application in . Turbopack starts up in  -  faster.","code-updates#Code updates":"As we continued to optimize Webpack, we found a performance ceiling on how much faster we could make Fast Refresh. With around 2,000 components, the best number we could produce was 500ms. This mark was a tremendous feat in Next.js 12. Previously, that process would have taken around 10 seconds.With Turbopack, we achieved the goal we were aiming for: Fast Refresh performance that stays near-constant, no matter your application size. Instead of scaling with your application size, it scales based on the size of the changes made.In a 1,000 module application, Turbopack can react to file changes  faster than Webpack. In a 30,000 module application, this is  faster.","extensibility#Extensibility":"Webpack has an extraordinary collection of plugins to customize its behavior. Composing plugins lets you create custom toolchains which can support a huge variety of bundler features.In its alpha state, Turbopack cannot currently be configured with plugins. In the future, we plan to make Turbopack just as extensible as Webpack - though likely with an altered API."}},"/terminal/docs/features/stocks":{"title":"Stocks","data":{"":"Turbopack supports TypeScript out of the box. This means you can import .ts files with Turbopack. We support all of TypeScript's feature set.Thanks to our JSX support, you can also import .tsx files too.","resolving-paths-and-baseurl#Resolving paths and baseUrl":"In TypeScript, you can use the paths property of tsconfig.json to let you import files from custom paths.\n{\n\"compilerOptions\": {\n\"baseUrl\": \"src\",\n\"paths\": {\n\"app/*\": [\"app/*\"],\n\"config/*\": [\"app/_config/*\"],\n\"shared/*\": [\"app/_shared/*\"],\n},\n}\nThis would let you import directly from app/* without needing to do a relative import:\n- import { add } from '../../../../../math';\n+ import { add } from 'app/math';\n\nadd();\nTurbopack reads the paths and baseUrl in tsconfig.json in order to resolve these paths, just like Next.js does.This means you only need to configure your absolute paths in one place.","type-checking#Type Checking":"Turbopack does not perform type checks on your application. We use SWC to compile TypeScript code, which also does not perform type checks.This means that in order to run your type checks, you'll need a sidecar process running tsc --watch. Or, you can rely on your IDE's TypeScript integration."}},"/terminal/docs/getting-started/add-to-project":{"title":"Installation","data":{"":"Turborepo can be used in any project to speed up the execution of scripts in your package.json.After you install turbo, you'll be able to run all your package.json tasks from turbo instead of your package manager.By configuring your turbo.json correctly, you'll notice how caching helps your tasks run a lot faster.","quickstart#Quickstart":"If you don't have one already, create a new application:\n\n\n\n\nnpx create-next-app@latest\n\n\n\nnpm create vite@latest\n\n\n\nInstall turbo:\n\n\n\n\nnpm install turbo --save-dev\n\n\n\nyarn add turbo --dev\n\n\n\npnpm install turbo --save-dev\n\n\n\nAdd a turbo.json file at the base of your new repository:\n\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\n\n\n\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\"]\n},\n\"lint\": {\n\"outputs\": []\n}\n}\n}\nSome Vite starters ship with a package.json that looks like this:\n{\n\"scripts\": {\n\"build\": \"tsc && vite build\"\n}\n}\nWe recommend splitting these into a lint and build script.\n{\n\"scripts\": {\n\"build\": \"vite build\",\n\"lint\": \"tsc\"\n}\n}\nThis means that Turbo can schedule them separately.\n\n\nTry running build and lint with turbo:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nThis runs build and lint at the same time.\nWithout making any changes to the code, try running build and lint again:\n\n\n\n\nnpx turbo build lint\n\n\n\nyarn turbo build lint\n\n\n\npnpm turbo build lint\n\n\nYou should see terminal output like this:\nTasks:    2 successful, 2 total\nCached:    2 cached, 2 total\nTime:    185ms >>> FULL TURBO\nCongratulations - you just completed a build and lint in under 200ms.To learn how this is possible, check out our core concepts docs.\nTry running dev with turbo:\n\n\n\n\nnpx turbo dev\n\n\n\nyarn turbo dev\n\n\n\npnpm turbo dev\n\n\nYou'll notice that your dev script starts up. You can use turbo to run any script in your package.json."}},"/terminal/docs/getting-started/existing-monorepo":{"title":"First commands","data":{"":"turbo works with Yarn, npm, and pnpm on the following operating systems:\nmacOS darwin 64-bit (Intel), ARM 64-bit (Apple Silicon)\nLinux 32-bit, 64-bit, ARM, ARM 64-bit, MIPS 64-bit Little Endian, PowerPC 64-bit Little Endian, IBM Z 64-bit Big Endian\nWindows 32-bit, 64-bit, ARM 64-bit\nFreeBSD 64-bit, ARM 64-bit\nNetBSD AMD64\nAndroid ARM 64-bit","configure-workspaces#Configure workspaces":"turbo is built on top of Workspaces, a way of managing multiple packages from within a single monorepo package. Turborepo is compatible with the workspace implementations from all package managers. For more information on managing your Turborepo workspaces, see the Workspaces documentation.You can configure workspaces any way you want, but a common folder structure example is keeping applications in the /apps folder and packages in the /packages folder. The configuration of these folders is different for each package manager.\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your workspaces in your monorepo's root package.json file:\n{\n\"workspaces\": [\"packages/*\", \"apps/*\"]\n}\n\n\n\n\nSpecify your packages in pnpm-workspace.yaml.\npackages:\n- \"packages/*\"\n- \"apps/*\"\n\n\nAfter configuring your workspaces, re-run your package manager's install command.\nNote: Nested workspaces are not supported. As package names are required to be\nunique, moving each package to be a child of the monorepo's root package\nshould meet your needs.","install-turbo#Install turbo":"Add turbo as a development dependency at the root of your monorepo.\n\n\nnpm install turbo -D\n\n\n\nyarn add turbo -DW\n\n\n\npnpm add turbo -Dw\n\n\nThe turbo package is a shell script that will install the proper turbo-<os>-<arch> package for your operating system and architecture.\nNote: Linux builds of turbo link against glibc. For Alpine Docker environments, you will need to ensure libc6-compat is installed as well, via RUN apk add --no-cache libc6-compat","create-turbojson#Create turbo.json":"In the root of your monorepo, create an empty file named turbo.json. This will hold the configuration for Turborepo.\n{\n\"$schema\": \"https://turbo.build/schema.json\"\n}","create-a-pipeline#Create a pipeline":"To define your monorepo's task dependency graph, use the pipeline key in the turbo.json configuration file at the root of monorepo. turbo interprets this configuration to optimally schedule, execute, and cache the outputs of each of the package.json scripts defined in your workspaces.Each key in the pipeline object is the name of a package.json script that can be executed by turbo run. You can specify its dependencies with the dependsOn key inside it as well as some other options related to caching. For more information on configuring your pipeline, see the Pipelines documentation.Workspaces that do not have the specified script defined in their package.json's list of scripts will be ignored by turbo.\n{\n\"$schema\": \"https://turbo.build/schema.json\",\n\"pipeline\": {\n\"build\": {\n// A package's `build` script depends on that package's\n// dependencies and devDependencies\n// `build` tasks  being completed first\n// (the `^` symbol signifies `upstream`).\n\"dependsOn\": [\"^build\"],\n// note: output globs are relative to each package's `package.json`\n// (and not the monorepo root)\n\"outputs\": [\".next/**\"]\n},\n\"test\": {\n// A package's `test` script depends on that package's\n// own `build` script being completed first.\n\"dependsOn\": [\"build\"],\n\"outputs\": [],\n// A package's `test` script should only be rerun when\n// either a `.tsx` or `.ts` file has changed in `src` or `test` folders.\n\"inputs\": [\"src/**/*.tsx\", \"src/**/*.ts\", \"test/**/*.ts\", \"test/**/*.tsx\"]\n},\n\"lint\": {\n// A package's `lint` script has no dependencies and\n// can be run whenever. It also has no filesystem outputs.\n\"outputs\": []\n},\n\"deploy\": {\n// A package's `deploy` script depends on the `build`,\n// `test`, and `lint` scripts of the same package\n// being completed. It also has no filesystem outputs.\n\"dependsOn\": [\"build\", \"test\", \"lint\"],\n\"outputs\": []\n}\n}\n}\nThe rough execution order for a given package is based on the dependsOn keys:\nbuild once its upstream dependencies have run their build commands\ntest once its own build command is finished and has no filesystem outputs (just logs) within a package\nlint runs in an arbitrary order as it has no upstream dependencies\ndeploy once its own build, test, and lint commands have finished.\n\nAfter execution, the full pipline can run:\nnpx turbo run build test lint deploy\nturbo will then schedule the execution of each task(s) to optimize usage of the machine's resources.","edit-gitignore#Edit .gitignore":"Add .turbo to your .gitignore file. The CLI uses these folders for logs and certain task outputs.\n+ .turbo\nMake sure that your task artifacts, the files and folders you want cached, are also included in your .gitignore.\n+ build/**\n+ dist/**\n+ .next/**\nRe-run your npm client's install command to check your configuration.","create-packagejson-scripts#Create package.json scripts":"Add or update scripts in your monorepo's root package.json file and have them delegate to turbo.\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"test\": \"turbo run test\",\n\"lint\": \"turbo run lint\",\n\"dev\": \"turbo run dev\"\n}\n}","build-your-monorepo#Build your monorepo":"npm run build\n\n\n\nyarn build\n\n\n\npnpm build\n\n\nDepending on your monorepo setup, some artifacts might already be caching properly. In the next sections, we'll show how turbo works, how scope works, and then how to get caching working after that.","configure-remote-caching#Configure Remote Caching":"A major key ðŸ”‘ to Turborepo's speed is that it is both lazy and efficientâ€”it does the least amount of work possible and it tries to never redo work that's already been done before.At the moment, Turborepo caches your tasks on your local filesystem (i.e. \"single-player mode,\" if you will). However, what if there was a way to take advantage of the computational work done by your teammates or your CI (i.e. \"co-op multiplayer mode\")? What if there was a way to teleport and share a single cache across machines? Almost like a \"Dropbox\" for your Turborepo cache.\nRemote Caching has entered the chat.\nTurborepo can use a technique known as Remote Caching to share cache artifacts across machines for an additional speed boost.\nRemote Caching is a powerful feature of Turborepo, but with great power comes\ngreat responsibility. Make sure you are caching correctly first and double\ncheck handling of environment variables. Please also remember Turborepo treats\nlogs as artifacts, so be aware of what you are printing to the console.","using-remote-caching-for-local-development#Using Remote Caching for Local development":"Turborepo uses Vercel as its default remote caching provider. If you want to link your local turborepo to your Remote Cache you can authenticate the Turborepo CLI with your Vercel account:\nnpx turbo login\nThen, link your turborepo to your remote cache:\nnpx turbo link\nOnce enabled, make some changes to a package or application you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache. To verify that this worked, delete your local Turborepo cache:\nrm -rf ./node_modules/.cache/turbo\nRun the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you.\nNote: When connecting to an sso-enabled Vercel team, you must provide your\nTeam slug as an argument to npx turbo login.\n\nnpx turbo login --sso-team=<team-slug>","next-steps#Next Steps":"You're now up and running with Turborepo, but there are still a few things to do:\nUnderstand how Turborepo caching works\nCorrectly handle environment variables\nLearn to orchestrate task running with pipelines\nEfficiently filter package tasks\nConfigure Turborepo with your CI provider"}},"/terminal/docs/getting-started/create-new":{"title":"Import","data":{"":"","quickstart#Quickstart":"To create a new monorepo, use our create-turbo npm package:\nnpx create-turbo@latest\nYou can also clone a Turborepo starter repository to get a head start on your monorepo. To see Turborepo examples and starters, see the Turborepo examples directory on GitHub.","full-tutorial#Full tutorial":"This tutorial will walk you through using the Turborepo basic example. By the end, you'll feel confident with using turbo, and know all the basic functionality.\nDuring this tutorial, some lines of code are omitted from the code samples. For instance, when showing a package.json we won't show all of the keys - only the ones that matter.","1-running-create-turbo#1. Running create-turbo":"First, run:\nnpx create-turbo@latest\nThis installs the create-turbo CLI, and runs it. You'll be asked several questions:","where-would-you-like-to-create-your-turborepo#Where would you like to create your turborepo?":"Choose anywhere you like. The default is ./my-turborepo.","which-package-manager-do-you-want-to-use#Which package manager do you want to use?":"Turborepo doesn't handle installing packages, so you'll need to choose either:\nnpm\npnpm\nyarn\n\nIf you're not sure, we recommend choosing pnpm. If you don't have it installed, cancel create-turbo (via ctrl-C) and take a look at the installation instructions.","installation#Installation":"Once you've picked a package manager, create-turbo will create a bunch of new files inside the folder name you picked. It'll also install all the dependencies that come with the basic example by default.","2-exploring-your-new-repo#2. Exploring your new repo":"You might have noticed something in the terminal. create-turbo gave you a description of all of the things it was adding.\n>>> Creating a new turborepo with the following:\n\n- apps/web: Next.js with TypeScript\n- apps/docs: Next.js with TypeScript\n- packages/ui: Shared React component library\n- packages/eslint-config-custom: Shared configuration (ESLint)\n- packages/tsconfig: Shared TypeScript `tsconfig.json`\nEach of these is a workspace - a folder containing a package.json. Each workspace can declare its own dependencies, run its own scripts, and export code for other workspaces to use.Open the root folder - ./my-turborepo - in your favourite code editor.","understanding-packagesui#Understanding packages/ui":"First, open ./packages/ui/package.json. You'll notice that the package's name is \"name\": \"ui\" - right at the top of the file.Next, open ./apps/web/package.json. You'll notice that this package's name is \"name\": \"web\". But also - take a look in its dependencies.You'll see that \"web\" depends on a package called \"ui\". If you're using pnpm, you'll see it's declared like this:\n{\n\"dependencies\": {\n\"ui\": \"workspace:*\"\n}\n}\nThis means that our web app depends on our local ui package.If you look inside apps/docs/package.json, you'll see the same thing. Both web and docs depend on ui - a shared component library.This pattern of sharing code across applications is extremely common in monorepos - and means that multiple apps can share a single design system.","understanding-imports-and-exports#Understanding imports and exports":"Take a look inside ./apps/docs/pages/index.tsx. Both docs and web are Next.js applications, and they both use the ui library in a similar way:\nimport { Button } from \"ui\";\n//       ^^^^^^         ^^\n\nexport default function Docs() {\nreturn (\n<div>\n<h1>Docs</h1>\n<Button />\n</div>\n);\n}\nThey're importing Button directly from a dependency called ui! How does that work? Where is Button coming from?Open packages/ui/package.json. You'll notice these two attributes:\n{\n\"main\": \"./index.tsx\",\n\"types\": \"./index.tsx\"\n}\nWhen workspaces import from ui, main tells them where to access the code they're importing. types tells them where the TypeScript types are located.So, let's look inside packages/ui/index.tsx:\nimport * as React from \"react\";\nexport * from \"./Button\";\nEverything inside this file will be able to be used by workspaces that depend on ui.index.tsx is exporting everything from a file called ./Button, so let's go there:\nimport * as React from \"react\";\n\nexport const Button = () => {\nreturn <button>Boop</button>;\n};\nWe've found our button! Any changes we make in this file will be shared across web and docs. Pretty cool!\nTry experimenting with exporting a different function from this file. Perhaps add(a, b) for adding two numbers together.This can then be imported by web and docs.","understanding-tsconfig#Understanding tsconfig":"We have two more workspaces to look at, tsconfig and eslint-config-custom. Each of these allow for shared configuration across the monorepo. Let's look in tsconfig:\n{\n\"name\": \"tsconfig\",\n\"files\": [\"base.json\", \"nextjs.json\", \"react-library.json\"]\n}\nHere, we specify three files to be exported, inside files. Packages which depend on tsconfig can then import them directly.For instance, packages/ui depends on tsconfig:\n{\n\"devDependencies\": {\n\"tsconfig\": \"workspace:*\"\n}\n}\nAnd inside its tsconfig.json file, it imports it using extends:\n{\n\"extends\": \"tsconfig/react-library.json\"\n}\nThis pattern allows for a monorepo to share a single tsconfig.json across all its workspaces, reducing code duplication.","understanding-eslint-config-custom#Understanding eslint-config-custom":"Our final workspace is eslint-config-custom.You'll notice that this is named slightly differently to the other workspaces. It's not as concise as ui or tsconfig. Let's take a look inside .eslintrc.js in the root of the monorepo to figure out why.\nmodule.exports = {\n// This tells ESLint to load the config from the workspace `eslint-config-custom`\nextends: [\"custom\"],\n};\nESLint resolves configuration files by looking for workspaces with the name eslint-config-*. This lets us write extends: ['custom'] and have ESLint find our local workspace.But why is this in the root of the monorepo?The way ESLint finds its configuration file is by looking at the closest .eslintrc.js. If it can't find one in the current directory, it'll look in the directory above until it finds one.So that means that if we're working on code inside packages/ui (which doesn't have a .eslintrc.js) it'll refer to the root instead.Apps that do have an .eslintrc.js can refer to custom in the same way. For instance, in docs:\nmodule.exports = {\nroot: true,\nextends: [\"custom\"],\n};\nJust like tsconfig, eslint-config-custom lets us share ESLint configs across our entire monorepo, keeping things consistent no matter what project you're working on.","summary#Summary":"It's important to understand the dependencies between these workspaces. Let's map them out:\nweb - depends on ui, tsconfig and eslint-config-custom\ndocs - depends on ui, tsconfig and eslint-config-custom\nui - depends on tsconfig and eslint-config-custom\ntsconfig - no dependencies\neslint-config-custom - no dependencies\n\nNote that the Turborepo CLI is not responsible for managing these dependencies. All of the things above are handled by the package manager you chose (npm, pnpm or yarn).","3-understanding-turbojson#3. Understanding turbo.json":"We now understand our repository and its dependencies. How does Turborepo help?Turborepo helps by making running tasks simpler and much more efficient.Let's take a look inside our root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev\",\n\"lint\": \"turbo run lint\"\n}\n}\nWe've got three tasks specified here in scripts which use turbo run. You'll notice that each of them is specified in turbo.json:\n{\n\"pipeline\": {\n\"build\": {\n//   ^^^^^\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\"dist/**\", \".next/**\"]\n},\n\"lint\": {\n//   ^^^^\n\"outputs\": []\n},\n\"dev\": {\n//   ^^^\n\"cache\": false\n}\n}\n}\nWhat we're seeing here is that we've registered three tasks with turbo - lint, dev and build. Every task that's registered inside turbo.json can be run with turbo run <task>.To see this in action, let's add a script to the root package.json:\n{\n\"scripts\": {\n\"build\": \"turbo run build\",\n\"dev\": \"turbo run dev --parallel\",\n\"lint\": \"turbo run lint\",\n+   \"hello\": \"turbo run hello\"\n}\n}\nNow, let's run hello.\n\n\nnpm run hello\n\n\n\nyarn hello\n\n\n\npnpm run hello\n\n\nYou'll see this error in the console:\ntask `hello` not found in turbo `pipeline` in \"turbo.json\".\nAre you sure you added it?\nThat's worth remembering - in order for turbo to run a task, it must be in turbo.json.Let's investigate the scripts we already have in place.","4-linting-with-turborepo#4. Linting with Turborepo":"Try running our lint script:\n\n\nnpm run lint\n\n\n\nyarn lint\n\n\n\npnpm run lint\n\n\nYou'll notice several things happen in the terminal.\nSeveral scripts will be run at the same time, each prefixed with either docs:lint, ui:lint or web:lint.\nThey'll each succeed, and you'll see 3 successful in the terminal.\nYou'll also see 0 cached, 3 total. We'll cover what this means later.\n\nThe scripts that each run come from each workspace's package.json. Each workspace can optionally specify its own lint script:\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"next lint\"\n}\n}\n\n{\n\"scripts\": {\n\"lint\": \"eslint *.ts*\"\n}\n}\nWhen we run turbo run lint, Turborepo looks at each lint script in each workspace and runs it. For more details, see our pipelines docs.","using-the-cache#Using the cache":"Let's run our lint script one more time. You'll notice a few new things appear in the terminal:\ncache hit, replaying output appears for docs:lint, web:lint and ui:lint.\nYou'll see 3 cached, 3 total.\nThe total runtime should be under 100ms, and >>> FULL TURBO appears.\n\nSomething interesting just happened. Turborepo realised that our code hadn't changed since the last time we ran the lint script.It had saved the logs from the previous run, so it just replayed them.Let's try changing some code to see what happens. Make a change to a file inside apps/docs:\nimport { Button } from \"ui\";\n\nexport default function Docs() {\nreturn (\n<div>\n-     <h1>Docs</h1>\n+     <h1>My great docs</h1>\n<Button />\n</div>\n);\n}\nNow, run the lint script again. You'll notice that:\ndocs:lint has a comment saying cache miss, executing. This means that docs is running its linting.\n2 cached, 3 total appears at the bottom.\n\nThis means that the results of our previous tasks were still cached. Only the lint script inside docs actually ran - again, speeding things up. To learn more, check out our caching docs.","5-building-with-turborepo#5. Building with Turborepo":"Let's try running our build script:\n\n\nnpm run build\n\n\n\nyarn build\n\n\n\npnpm run build\n\n\nYou'll see similar outputs to when we ran our lint script. Only apps/docs and apps/web specify a build script in their package.json, so only those are run.Take a look inside build in turbo.json. There's some interesting config there.\n{\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\".next/**\"]\n}\n}\n}\nYou'll notice that some outputs have been specified. Declaring outputs will mean that when turbo finishes running your task, it'll save the output you specify in its cache.Both apps/docs and apps/web are Next.js apps, and they output builds to the ./.next folder.Let's try something. Delete the apps/docs/.next build folder.Run the build script again. You'll notice:\nWe hit FULL TURBO - the builds complete in under 100ms.\nThe .next folder re-appears!\n\nTurborepo cached the result of our previous build. When we ran the build command again, it restored the entire .next/** folder from the cache. To learn more, check out our docs on cache outputs.","6-running-dev-scripts#6. Running dev scripts":"Let's now try running dev.\n\n\nnpm run dev\n\n\n\nyarn dev\n\n\n\npnpm run dev\n\n\nYou'll notice some information in the terminal:\nOnly two scripts will execute - docs:dev and web:dev. These are the only two workspaces which specify dev.\nBoth dev scripts are run simultaneously, starting your Next.js apps on ports 3000 and 3001.\nIn the terminal, you'll see cache bypass, force executing.\n\nTry quitting out of the script, and re-running it. You'll notice we don't go FULL TURBO. Why is that?Take a look at turbo.json:\n{\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}\nInside dev, we've specified \"cache\": false. This means we're telling Turborepo not to cache the results of the dev script. dev runs a persistent dev server and produces no outputs, so caching it makes no sense. Learn more about in our docs on turning off caching.","running-dev-on-only-one-workspace-at-a-time#Running dev on only one workspace at a time":"By default, turbo run dev will run dev on all workspaces at once. But sometimes, we might only want to choose one workspace.To handle this, we can add a --filter flag to our command. This --filter gets passed to the turbo CLI.\n\n\nnpm run dev -- --filter docs\n\n\n\nyarn dev --filter docs\n\n\n\npnpm run dev --filter docs\n\n\nYou'll notice that it now only runs docs:dev. Learn more about filtering workspaces from our docs.","summary-1#Summary":"Well done! You've learned all about your new monorepo, and how Turborepo makes handling your tasks easier.","next-steps#Next steps":"Need to add more tasks? Learn more about using pipelines\nWant to speed up your CI? Set up remote caching.\nWant some inspiration? Take a look at our directory of examples"}}}